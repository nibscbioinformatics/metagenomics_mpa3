#!/usr/bin/env bash


### Workflow for shotgun metagenomics analysis

## Root folder name
NAME=nibsc_metagenomics

echo "Please Check File Paths in main_metagenomics.sh"

## data file locations
READS='/home/AD/mgordon/PROJECTS/Microbiome_Project/31_03_21_Shotgun_Sequencing/rawdata' #your data
LINKPATH_DB='/home/AD/mgordon/PROJECTS/Microbiome_Project/31_03_21_Shotgun_Sequencing/metagenomics_mpa3/reference' #change path
 
## metagenomics analysis workflow - comment out to remove process

metagenomics_analysis_main(){
   
   create_folders 
   set_variables # -> Never comment this function
   #fetch_example_data # -> Uncomment this function if you want to run pipeline on test data. NOT Finished! need data in NIBSC format
   copy_rawdata
   activate_conda
   run_bbduk 
   run_seqtk
   run_metaphlan
   echo $LINKPATH_DB
}


create_folders(){

   echo "Creating sub-folders..."

   # Sub-folders in the root folder
   for FOLDER in analysis tools rawdata scripts docs reference
   do
      mkdir -p ${NAME}/${FOLDER}
   done
   echo "DONE creating sub-folders!"
}


# setting variable path
set_variables(){
   echo "Setting variables for paths..."

   export ROOT_FOLDER_NAME=${NAME}
   export TOOLS_FOLDER=$(pwd)/$ROOT_FOLDER_NAME/tools
   export RAWDATA_FOLDER=$(pwd)/$ROOT_FOLDER_NAME/rawdata
   export ANALYSIS_FOLDER=$(pwd)/$ROOT_FOLDER_NAME/analysis
   export REFERENCE_FOLDER=$(pwd)/$ROOT_FOLDER_NAME/reference
   export DOCS_FOLDER=$(pwd)//$ROOT_FOLDER_NAME/docs
   export SCRIPT_FOLDER=$(pwd)//$ROOT_FOLDER_NAME/scripts
   export LINKPATH_DB=$LINKPATH_DB
   echo "DONE setting variables for paths!"

   #soft link files
   echo "Ordering Folders"
   mkdir -p ${DOCS_FOLDER}/BBDUK_adapters
   ln -s $(pwd)/docs/adapters.fa ${DOCS_FOLDER}/BBDUK_adapters/ 
}

# copy raw data from source 

copy_rawdata(){

   lst=$(ls -d ${READS}/*.fastq.gz)
   for file in $lst
   do
      echo "Copying ${file}"
      cp ${file} ${RAWDATA_FOLDER}/
   done
   echo "DONE copying rawdata!"
}

# run pipeline using test data (uncomment above)
# paired reads from Chrysi exp used for testing

fetch_example_data(){

   mkdir -p $NAME/example_data

   cd $NAME/example_data


#   wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR114/039/SRR11487939/SRR11487939_1.fastq.gz
#   wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR114/039/SRR11487939/SRR11487939_2.fastq.gz

   SRC_RAWDATA=$NAME/example_data
   cd -
}

# Activate conda env for the pipeline
# Built env in prepare_metaphlan.sh as only needs to be run once

activate_conda(){
	
   eval "$(conda shell.bash hook)" #conda activation - more general than source..
   # bash script generated by 'conda shell.bash hook' is executed - this script defines conda behaviours
	conda activate metaphlan3
	
}

# Run bbduk adapter & quality trimming

run_bbduk(){
   echo "Running BBDuk Adapter & Quality Trimming"

   . ./scripts/run_bbduk.sh

   echo "DONE Trimming!"
   cd -

}

# Run seqtk subsampling & merging

run_seqtk(){
   echo "Running Seqtk Subsampling & Read Merging"

   . ./scripts/run_seqtk.sh

   echo "DONE Subsampling & Merging!"
   cd -
}

#  Run metaphlan3 taxonomic classification

run_metaphlan(){
   echo "Running Metaphlan3 Taxonomic Classification"

   . ./scripts/run_metaphlan.sh

   echo "DONE Metaphlan3 Taxonomic Classification!"
}


# run pipeline

metagenomics_analysis_main
